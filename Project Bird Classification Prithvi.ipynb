{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6879ef6e",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "72c2db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.image import imread\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import VGG16, MobileNetV2\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6968216d",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a1b93709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories for training, testing, validation and prediction datasets\n",
    "train_dir = '/Users/prithvishams/Documents/Bootcamp Concordia/Project Bird Classification/Bird Data/train'\n",
    "test_dir = '/Users/prithvishams/Documents/Bootcamp Concordia/Project Bird Classification/Bird Data/test'\n",
    "val_dir = '/Users/prithvishams/Documents/Bootcamp Concordia/Project Bird Classification/Bird Data/valid'\n",
    "predict_dir = '/Users/prithvishams/Documents/Bootcamp Concordia/Project Bird Classification/Bird Data/predict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cd59248c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model parameters\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "num_classes = len([d for d in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, d))])\n",
    "\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4c47bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for training\n",
    "train_img_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# No augmentation for val/test data\n",
    "val_test_img_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d1c73818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3208 images belonging to 20 classes.\n",
      "Found 100 images belonging to 20 classes.\n",
      "Found 100 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "train_data = train_img_gen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "# Load validation data\n",
    "val_data = val_test_img_gen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "# Load test data\n",
    "test_data = val_test_img_gen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d23a1c4",
   "metadata": {},
   "source": [
    "# Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9d36b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MobileNetV2 model with pre-trained weights\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "# Freeze the base model\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f511cd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom layers on top of the base model\n",
    "input_layer = layers.Input(shape=(224, 224, 3)) #input layer\n",
    "x = base_model(input_layer, training = False) #base model runs in inference mode\n",
    "x = layers.GlobalAveragePooling2D()(x) # flattens 7x7x1280 to 1280 by taking average of each 7x7 block\n",
    "x = layers.Dropout(0.2)(x) # dropout layer to prevent overfitting\n",
    "output_layer = layers.Dense(num_classes, activation='softmax')(x) # output layer with softmax activation\n",
    "\n",
    "# Create the model\n",
    "model = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7da6c55",
   "metadata": {},
   "source": [
    "# Compile and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d45898b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ebc20347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 211ms/step - accuracy: 0.4220 - loss: 2.0941 - val_accuracy: 0.9000 - val_loss: 0.3788\n",
      "Epoch 2/10\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 213ms/step - accuracy: 0.8836 - loss: 0.4494 - val_accuracy: 0.9300 - val_loss: 0.2436\n",
      "Epoch 3/10\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 221ms/step - accuracy: 0.9153 - loss: 0.3085 - val_accuracy: 0.9400 - val_loss: 0.1779\n",
      "Epoch 4/10\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 229ms/step - accuracy: 0.9252 - loss: 0.2602 - val_accuracy: 0.9300 - val_loss: 0.1649\n",
      "Epoch 5/10\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 236ms/step - accuracy: 0.9331 - loss: 0.2202 - val_accuracy: 0.9500 - val_loss: 0.1603\n",
      "Epoch 6/10\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 239ms/step - accuracy: 0.9413 - loss: 0.2043 - val_accuracy: 0.9600 - val_loss: 0.1429\n",
      "Epoch 7/10\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 241ms/step - accuracy: 0.9510 - loss: 0.1594 - val_accuracy: 0.9600 - val_loss: 0.1369\n",
      "Epoch 8/10\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 244ms/step - accuracy: 0.9668 - loss: 0.1307 - val_accuracy: 0.9500 - val_loss: 0.1288\n",
      "Epoch 9/10\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 243ms/step - accuracy: 0.9607 - loss: 0.1380 - val_accuracy: 0.9400 - val_loss: 0.1368\n",
      "Epoch 10/10\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 243ms/step - accuracy: 0.9548 - loss: 0.1374 - val_accuracy: 0.9600 - val_loss: 0.1083\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4)\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "17892f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.9753 - loss: 0.0613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.050866927951574326\n",
      "Test Accuracy: 98.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on Test Data\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy*100:.2f}%')\n",
    "\n",
    "# Save the model\n",
    "model.save('bird_classification_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11640ce4",
   "metadata": {},
   "source": [
    "# Predict New Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d9ce3a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 files.\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n"
     ]
    }
   ],
   "source": [
    "# Load Prediction Images\n",
    "predict_data = keras.utils.image_dataset_from_directory(\n",
    "    predict_dir,\n",
    "    labels=None,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=1,\n",
    "    shuffle=False\n",
    ") # no subdirectory required when labels = None\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(predict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ca425c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 20)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1ff666f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 11, 11, 11, 11, 17])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predicted class indices\n",
    "predicted_class_indices = np.argmax(predictions, axis=1)\n",
    "predicted_class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e4bbf73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABBOTTS BABBLER',\n",
       " 'ABBOTTS BOOBY',\n",
       " 'ABYSSINIAN GROUND HORNBILL',\n",
       " 'AFRICAN CROWNED CRANE',\n",
       " 'AFRICAN EMERALD CUCKOO',\n",
       " 'AFRICAN FIREFINCH',\n",
       " 'AFRICAN OYSTER CATCHER',\n",
       " 'AFRICAN PIED HORNBILL',\n",
       " 'AFRICAN PYGMY GOOSE',\n",
       " 'ALBATROSS',\n",
       " 'ALBERTS TOWHEE',\n",
       " 'ALEXANDRINE PARAKEET',\n",
       " 'ALPINE CHOUGH',\n",
       " 'ALTAMIRA YELLOWTHROAT',\n",
       " 'AMERICAN AVOCET',\n",
       " 'AMERICAN BITTERN',\n",
       " 'AMERICAN COOT',\n",
       " 'AMERICAN FLAMINGO',\n",
       " 'AMERICAN GOLDFINCH',\n",
       " 'AMERICAN KESTREL']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map class indices to class labels\n",
    "class_names = list(train_data.class_indices.keys())\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b48d8a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Predicted Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>ALEXANDRINE PARAKEET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>ALEXANDRINE PARAKEET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>ALEXANDRINE PARAKEET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>ALEXANDRINE PARAKEET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.jpg</td>\n",
       "      <td>ALEXANDRINE PARAKEET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.jpg</td>\n",
       "      <td>AMERICAN FLAMINGO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Image       Predicted Label\n",
       "0  1.jpg  ALEXANDRINE PARAKEET\n",
       "1  2.jpg  ALEXANDRINE PARAKEET\n",
       "2  3.jpg  ALEXANDRINE PARAKEET\n",
       "3  4.jpg  ALEXANDRINE PARAKEET\n",
       "4  5.jpg  ALEXANDRINE PARAKEET\n",
       "5  6.jpg     AMERICAN FLAMINGO"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = [class_names[i] for i in predicted_class_indices]\n",
    "predicted_labels\n",
    "# Create a DataFrame for predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Image': [os.path.basename(f) for f in predict_data.file_paths],\n",
    "    'Predicted Label': predicted_labels\n",
    "})\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65b70d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
